{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d91f84f",
   "metadata": {},
   "source": [
    "# Elective Project\n",
    "## Amazon Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c6439f",
   "metadata": {},
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e6eb4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-surprise in /Users/lukeroberts/anaconda3/lib/python3.12/site-packages (1.1.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/lukeroberts/anaconda3/lib/python3.12/site-packages (from scikit-surprise) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/lukeroberts/anaconda3/lib/python3.12/site-packages (from scikit-surprise) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/lukeroberts/anaconda3/lib/python3.12/site-packages (from scikit-surprise) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /Users/lukeroberts/anaconda3/lib/python3.12/site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in /Users/lukeroberts/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/lukeroberts/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: setuptools in /Users/lukeroberts/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/lukeroberts/anaconda3/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/lukeroberts/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/lukeroberts/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/lukeroberts/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/lukeroberts/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/lukeroberts/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install libraries\n",
    "\n",
    "%pip install scikit-surprise\n",
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aebb81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.26.4\n",
      "Pandas version: 2.2.2\n",
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# base libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ml\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# error handling\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f'NumPy version: {np.__version__}')\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "print('All libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0908b1",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "214c0195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data = pd.read_csv(\"/Users/lukeroberts/My Drive(lukejrobertsza@gmail.com)/Colab Notebooks/mit_adsp_notebooks/7.1.elective_project/ratings_Electronics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86cfcd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the data\n",
    "copy_of_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d81dfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign column headers without replacing the first row\n",
    "data.columns = ['user', 'item', 'rating', 'timestamp']\n",
    "copy_of_data.columns = ['user', 'item', 'rating', 'timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed92aaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop timestamp from data and copy_of_data\n",
    "\n",
    "data = data.drop(columns='timestamp')\n",
    "copy_of_data = copy_of_data.drop(columns='timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c88e156",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e46a1d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_unique_values(df):\n",
    "    \"\"\"\n",
    "    Returns a dictionary with column names as keys and lists of unique values as values.\n",
    "    Also prints the count of unique values per column.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame to analyze\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with column names as keys and unique values as values\n",
    "    \"\"\"\n",
    "    unique_values = {}\n",
    "    print(\"Number of unique values per column:\")\n",
    "    for column in df.columns:\n",
    "        uniques = df[column].unique()\n",
    "        unique_values[column] = uniques\n",
    "        print(f\"{column}: {len(uniques):,} unique values\")\n",
    "    \n",
    "    return unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9a983f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values per column:\n",
      "user: 4,201,696 unique values\n",
      "item: 476,001 unique values\n",
      "rating: 5 unique values\n"
     ]
    }
   ],
   "source": [
    "# Test the function on the data\n",
    "unique_data = function_unique_values(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf801300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_sparsity(df):\n",
    "    \"\"\"\n",
    "    Calculate the sparsity of a user-item interaction matrix.\n",
    "    \n",
    "    Sparsity is defined as: 1 - (number of observed interactions / total possible interactions)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing user-item interactions\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Sparsity value between 0 and 1, where higher values indicate more sparsity\n",
    "    \"\"\"\n",
    "    # Count unique users and items\n",
    "    n_users = df['user'].nunique()\n",
    "    n_items = df['item'].nunique()\n",
    "    \n",
    "    # Total possible interactions\n",
    "    total_possible = n_users * n_items\n",
    "    \n",
    "    # Number of observed interactions\n",
    "    observed = len(df)\n",
    "    \n",
    "    # Calculate sparsity\n",
    "    sparsity = 1 - (observed / total_possible)\n",
    "    \n",
    "    print(f\"Number of users: {n_users:,}\")\n",
    "    print(f\"Number of items: {n_items:,}\")\n",
    "    print(f\"Number of observed interactions: {observed:,}\")\n",
    "    print(f\"Number of possible interactions: {total_possible:,}\")\n",
    "    print(f\"Matrix sparsity: {sparsity:.6f} ({sparsity:.4%})\")\n",
    "    \n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9c88c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 4,201,696\n",
      "Number of items: 476,001\n",
      "Number of observed interactions: 7,824,481\n",
      "Number of possible interactions: 2,000,011,497,696\n",
      "Matrix sparsity: 0.999996 (99.9996%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999960877819908"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_sparsity(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1df076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter users who have rated 20 or more items\n",
    "user_rating_counts = data.groupby('user').size()\n",
    "users_with_20_or_more_ratings = user_rating_counts[user_rating_counts >= 20].index\n",
    "filtered_data_by_users = data[data['user'].isin(users_with_20_or_more_ratings)]\n",
    "\n",
    "# Step 2: Filter items that have been rated by 20 or more users\n",
    "item_rating_counts = filtered_data_by_users.groupby('item').size()\n",
    "items_with_20_or_more_ratings = item_rating_counts[item_rating_counts >= 20].index\n",
    "final_filtered_data = filtered_data_by_users[filtered_data_by_users['item'].isin(items_with_20_or_more_ratings)]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Original data shape: {data.shape}\")\n",
    "print(f\"Filtered data shape after user threshold: {filtered_data_by_users.shape}\")\n",
    "print(f\"Final filtered data shape after item threshold: {final_filtered_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119bfd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reapply the user filter to ensure only users with 20 or more ratings are retained\n",
    "users_with_20_or_more_ratings = final_filtered_data['user'].value_counts()\n",
    "users_with_20_or_more_ratings = users_with_20_or_more_ratings[users_with_20_or_more_ratings >= 20].index\n",
    "\n",
    "# Filter the final_filtered_data to include only these users\n",
    "final_filtered_data = final_filtered_data[final_filtered_data['user'].isin(users_with_20_or_more_ratings)]\n",
    "\n",
    "# Verify the results\n",
    "print(f\"Final filtered data shape: {final_filtered_data.shape}\")\n",
    "print(f\"Number of unique users: {final_filtered_data['user'].nunique()}\")\n",
    "print(f\"Minimum ratings per user: {final_filtered_data.groupby('user').size().min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c8a377",
   "metadata": {},
   "source": [
    "### Start Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89046869",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd6b43a",
   "metadata": {},
   "source": [
    "#### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6debde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create user filtering\n",
    "\n",
    "# list of all users\n",
    "list_of_users = data['user']\n",
    "\n",
    "# dictionary to store users in\n",
    "dictionary_users = {}\n",
    "\n",
    "# loop to count users' ratings\n",
    "for user in list_of_users:\n",
    "\n",
    "    # add +1 if the user is already in the dictionary\n",
    "    if user in dictionary_users:\n",
    "        dictionary_users[user] +=1\n",
    "\n",
    "    # otherwise let the user = 1\n",
    "    else:\n",
    "        dictionary_users[user] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb0f227f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users to remove: 4,188,345\n",
      "Percentage of users to remove: 99.68%\n"
     ]
    }
   ],
   "source": [
    "# apply user filter\n",
    "\n",
    "# set threshold\n",
    "THRESHOLD_USER = 20\n",
    "\n",
    "# empty list for users below the threshold\n",
    "remove_users_below_threshold = []\n",
    "\n",
    "# set for loop\n",
    "# iterate through the dictionary to find users with fewer ratings than threshold\n",
    "for user, rating_count in dictionary_users.items():\n",
    "    if rating_count < THRESHOLD_USER:\n",
    "        remove_users_below_threshold.append(user)\n",
    "\n",
    "# print results\n",
    "print(f\"Number of users to remove: {len(remove_users_below_threshold):,}\")\n",
    "print(f\"Percentage of users to remove: {len(remove_users_below_threshold) / len(dictionary_users):.2%}\")\n",
    "# Filter the data to keep only users with ratings >= THRESHOLD_USER\n",
    "filtered_data = data[~data['user'].isin(remove_users_below_threshold)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c3379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data to keep only users with ratings >= THRESHOLD_USER\n",
    "filtered_data = data[~data['user'].isin(remove_users_below_threshold)]\n",
    "\n",
    "# Print the new dataframe info and reduction stats\n",
    "print(f\"Original data shape: {data.shape}\")\n",
    "print(f\"Filtered data shape: {filtered_data.shape}\")\n",
    "print(f\"Reduction: {(1 - len(filtered_data)/len(data)):.2%} of data removed\")\n",
    "\n",
    "# Check sparsity of the filtered data\n",
    "print(\"\\nUnique values after user filtering:\")\n",
    "function_unique_values(filtered_data)\n",
    "print(\"\\nSparsity after user filtering:\")\n",
    "function_sparsity(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a88fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018a8a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.DataFrame(filtered_data.groupby('user').count().sort_values(by='rating', ascending=True))\n",
    "user_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efbf813",
   "metadata": {},
   "source": [
    "#### Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbe88cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create item filtering\n",
    "\n",
    "# list of items\n",
    "list_of_items = data['item']\n",
    "\n",
    "# Dictionary to store item counts\n",
    "dictionary_items = {}\n",
    "\n",
    "# Loop to count items' occurrences\n",
    "for item in list_of_items:\n",
    "    if item in dictionary_items:\n",
    "        dictionary_items[item] += 1\n",
    "    else:\n",
    "        dictionary_items[item] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354795b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply item filter\n",
    "\n",
    "# set threshold\n",
    "THRESHOLD_ITEM = 10\n",
    "\n",
    "# empty list for items below the threshold\n",
    "remove_items_below_threshold = []\n",
    "\n",
    "# set for loop\n",
    "# iterate through the dictionary to find items with fewer ratings than threshold\n",
    "for item, item_rating_count in dictionary_items.items():\n",
    "    if item_rating_count < THRESHOLD_ITEM:\n",
    "        remove_items_below_threshold.append(item)\n",
    "\n",
    "# print results\n",
    "print(f\"Number of items to remove: {len(remove_items_below_threshold):,}\")\n",
    "print(f\"Percentage of items to remove: {len(remove_items_below_threshold) / len(dictionary_items):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc7064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data to keep only items with ratings >= THRESHOLD_ITEM\n",
    "final_filtered_data = data[~data['item'].isin(remove_items_below_threshold)]\n",
    "\n",
    "# Print the new dataframe info and reduction stats\n",
    "print(f\"Data before user filtering: {data.shape}\")\n",
    "print(f\"Data after user filtering: {filtered_data.shape}\")\n",
    "print(f\"Data after item filtering: {final_filtered_data.shape}\")\n",
    "print(f\"Total reduction: {(1 - len(final_filtered_data)/len(data)):.2%} of original data removed\")\n",
    "\n",
    "# Check sparsity of the final filtered data\n",
    "print(\"\\nUnique values after item filtering:\")\n",
    "function_unique_values(final_filtered_data)\n",
    "print(\"\\nSparsity after item filtering:\")\n",
    "function_sparsity(final_filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87157067",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df = pd.DataFrame(final_filtered_data.groupby('item').count().sort_values(by='user', ascending=True))\n",
    "item_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad51821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_df.shape, item_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd86e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_matrix_merged = pd.merge(user_df, item_df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9149e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_matrix_merged.groupby('user').count().sort_values(by='rating', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271e48f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
